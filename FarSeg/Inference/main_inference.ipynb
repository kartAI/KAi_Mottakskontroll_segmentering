{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from Data.pre_processing import get_random_geotiff, generate_tiles\n",
    "from Data.post_processing import clear_output_directory, merge_images\n",
    "from Model.farseg_model import initialize_model\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing **folders** and **paths**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to model\n",
    "modelPath = 'C:/Users/jshjelse/Documents/Prosjektoppgave/Model/trained_farseg_model_ByggVei_3.pth'\n",
    "ortophoto_path = 'C:/images_mj'\n",
    "tile_folder = './FarSeg/Inference/Tiles/tiles'\n",
    "segmented_output_dir = './FarSeg/Inference/Tiles/segmented'\n",
    "\n",
    "# Ensuring that the folders exists:\n",
    "os.makedirs(tile_folder, exist_ok=True)\n",
    "os.makedirs(segmented_output_dir, exist_ok=True)\n",
    "\n",
    "# Prepare the folders for a new job:\n",
    "clear_output_directory(tile_folder)\n",
    "clear_output_directory(segmented_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates **device**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches GPU or CPU device:\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploads the **trained model**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the trained model\n",
    "num_classes = 3\n",
    "model, _, _ = initialize_model(num_classes)\n",
    "model.load_state_dict(torch.load(modelPath, weights_only=True))  # Load the model from the saved file\n",
    "model = model.to(device)\n",
    "print(\"Model successfully loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes **colours** and **classes**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a color map for the specified number of classes\n",
    "color_map = {\n",
    "            0: [0, 0, 0],        # Background - Black\n",
    "            1: [255, 0, 0],      # Buildings - Red\n",
    "            2: [255, 255, 0]     # Roads - Yellow\n",
    "        }\n",
    "\n",
    "# Convert the color map dictionary to a NumPy array\n",
    "colors = np.array([color_map[i] for i in range(num_classes)], dtype=np.uint8) # Return RGB colors\n",
    "\n",
    "# Define class names for the legend\n",
    "class_names = [\"Background\", \"Building\", \"Road\"]\n",
    "\n",
    "# Creates output folder:\n",
    "output_folder = './FarSeg/Inference/Final result/'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetches the **GeoTIFFs**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotiff_paths = glob.glob(ortophoto_path + '/*.tif')\n",
    "geotiff_paths = geotiff_paths[int(0.9 * len(geotiff_paths)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterates over all the GeoTIFFs doing the following:\n",
    "\n",
    "- Splitting each into tiles\n",
    "\n",
    "- Performe predictions on all the tiles\n",
    "\n",
    "- Merges all the tiles together again\n",
    "\n",
    "- Savs output and original image as .tif and .jpg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, path in enumerate(geotiff_paths):\n",
    "    new_geotiff_path = get_random_geotiff(ortophoto_path)\n",
    "    print(\"GeoTIFF fetched at: \" + str(new_geotiff_path))\n",
    "\n",
    "    # Generate tiles from the input GeoTIFF\n",
    "    generate_tiles(new_geotiff_path, tile_folder)\n",
    "\n",
    "    splitted_geotiffs = [os.path.join(tile_folder, f) for f in os.listdir(tile_folder) if f.endswith('.tif')]\n",
    "\n",
    "    for i, geotiff in tqdm(enumerate(splitted_geotiffs), \"GeoTIFFs\"):\n",
    "        with rasterio.open(geotiff) as src: \n",
    "            # Read image bands as a numpy array\n",
    "            image = src.read().astype(np.float32)  # Shape: (bands, height, width)\n",
    "            profile = src.profile\n",
    "\n",
    "        # The input is a NumPy array of shape (bands, height, width).\n",
    "        # Convert it to the shape expected by torchvision (height, width, bands).\n",
    "        image = np.moveaxis(image, 0, -1)\n",
    "\n",
    "        # Check if the image has 3 bands (for RGB). If not, adapt the normalization dynamically.\n",
    "        if image.shape[2] == 3:  # Assuming RGB\n",
    "            transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            # Use mean and std = 0.5 for each channel as a default for other cases\n",
    "            channels = image.shape[2]\n",
    "            mean = [0.5] * channels\n",
    "            std = [0.5] * channels\n",
    "            transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=mean, std=std)\n",
    "            ])\n",
    "\n",
    "        # Apply the transform (ToTensor converts image to shape: (bands, height, width))\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device) # Add batch dimension for model input\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image_tensor) # Forward pass through the model\n",
    "            predicted_segmented_mask = output.squeeze(0).argmax(0).cpu().numpy() # Shape: (height, width)\n",
    "\n",
    "        # Create an RGB image from the segmentation classes\n",
    "        segmented_image_rgb = colors[predicted_segmented_mask]\n",
    "\n",
    "        # Update the profile to save as RGB GeoTIFF\n",
    "        profile.update({\n",
    "            'count': 3, # 3 channels for RGB\n",
    "            'dtype': 'uint8',\n",
    "            'photometric': 'RGB'\n",
    "        })\n",
    "\n",
    "        # Save as GeoTIFF\n",
    "        output_filename = os.path.splitext(os.path.basename(geotiff))[0] + '_segmented.tif'\n",
    "        geotiff_output_filepath = os.path.join(segmented_output_dir, output_filename)\n",
    "        with rasterio.open(\n",
    "            geotiff_output_filepath,\n",
    "            'w',\n",
    "            **profile\n",
    "        ) as dst:\n",
    "            dst.write(segmented_image_rgb[:, :, 0], 1) # Red channel\n",
    "            dst.write(segmented_image_rgb[:, :, 1], 2) # Green channel\n",
    "            dst.write(segmented_image_rgb[:, :, 2], 3) # Blue channel\n",
    "\n",
    "    # Merge all tiles into a final combined image\n",
    "    output_original = f'C:/Users/jshjelse/Documents/Prosjektoppgave/FarSeg/inference/Final result/merged_original_tif_{k}.tif'\n",
    "    output_segmented = f'C:/Users/jshjelse/Documents/Prosjektoppgave/FarSeg/inference/Final result/merged_segmented_tif_{k}.tif'\n",
    "\n",
    "    merge_images(tile_folder, segmented_output_dir, output_original, output_segmented)\n",
    "\n",
    "    # Clean up the output directories\n",
    "    clear_output_directory(tile_folder)\n",
    "    clear_output_directory(segmented_output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
